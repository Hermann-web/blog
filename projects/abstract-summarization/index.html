<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="This project explores various automatic summarization techniques, emphasizing pre-trained models and fine-tuning."><meta name=author content="Hermann Agossou"><link href=https://hermann-agossou.com/projects/abstract-summarization/ rel=canonical><link href=../introducing-lissajou-for-animated-plots/ rel=prev><link href=../bot_detection_in_auction/ rel=next><link rel=icon href=../../assets/logo-blog-hermann-agossou-ot0-500x500.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.0"><title>NLP Project: Summarization - What I learned today (@hermann-web)</title><link rel=stylesheet href=../../assets/stylesheets/main.618322db.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../css/timeago.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css><link rel=stylesheet href=../../stylesheets/float-img.css><link rel=stylesheet href=../../stylesheets/custom-admonition.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#nlp-project-summarization class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="What I learned today (@hermann-web)" class="md-header__button md-logo" aria-label="What I learned today (@hermann-web)" data-md-component=logo> <img src=../../assets/logo-blog-hermann-agossou-ot20-500x500.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> What I learned today (@hermann-web) </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> NLP Project: Summarization </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/hermann-web/blog/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> hermann-web/blog </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Projects </a> </li> <li class=md-tabs__item> <a href=../../blog/ class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="What I learned today (@hermann-web)" class="md-nav__button md-logo" aria-label="What I learned today (@hermann-web)" data-md-component=logo> <img src=../../assets/logo-blog-hermann-agossou-ot20-500x500.png alt=logo> </a> What I learned today (@hermann-web) </label> <div class=md-nav__source> <a href=https://github.com/hermann-web/blog/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> hermann-web/blog </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Projects </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Projects </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../bot_detection_in_auction/ class=md-nav__link> <span class=md-ellipsis> Bots Detection in Auction </span> </a> </li> <li class=md-nav__item> <a href=../search-engine-for-domain-specific-french-users/ class=md-nav__link> <span class=md-ellipsis> Search Engine in french </span> </a> </li> <li class=md-nav__item> <a href=../file-hosting-app/ class=md-nav__link> <span class=md-ellipsis> Flask based File Hosting (web app & api & python module & cli app) </span> </a> </li> <li class=md-nav__item> <a href=../image-to-latex-formula/ class=md-nav__link> <span class=md-ellipsis> Streamlit App for Formula OCR using pix2tex </span> </a> </li> <li class=md-nav__item> <a href=../introducing-two-new-packages-for-streamlining-file-conversions-in-python/ class=md-nav__link> <span class=md-ellipsis> Introducing Two New Packages for Streamlining File Conversions in Python </span> </a> </li> <li class=md-nav__item> <a href=../introducing-lissajou-for-animated-plots/ class=md-nav__link> <span class=md-ellipsis> Introducing the `lissajou` Package for Image and 2D/3D Plot Animation </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Abstract Summarization </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Abstract Summarization </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-introduction class=md-nav__link> <span class=md-ellipsis> 1 Introduction </span> </a> </li> <li class=md-nav__item> <a href=#2-evaluation-metrics class=md-nav__link> <span class=md-ellipsis> 2 Evaluation metrics </span> </a> </li> <li class=md-nav__item> <a href=#3-approach-1 class=md-nav__link> <span class=md-ellipsis> 3 Approach 1 </span> </a> <nav class=md-nav aria-label="3 Approach 1"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-used-models class=md-nav__link> <span class=md-ellipsis> 3.1 Used Models </span> </a> </li> <li class=md-nav__item> <a href=#32-steps-for-generating-summaries class=md-nav__link> <span class=md-ellipsis> 3.2 Steps for generating summaries </span> </a> </li> <li class=md-nav__item> <a href=#33-results-on-train-dataset class=md-nav__link> <span class=md-ellipsis> 3.3 Results on train dataset </span> </a> </li> <li class=md-nav__item> <a href=#34-fine-tuning class=md-nav__link> <span class=md-ellipsis> 3.4 Fine-tuning </span> </a> </li> <li class=md-nav__item> <a href=#35-evaluation-and-discussion class=md-nav__link> <span class=md-ellipsis> 3.5 Evaluation and discussion </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-approach-2 class=md-nav__link> <span class=md-ellipsis> 4 Approach 2 </span> </a> <nav class=md-nav aria-label="4 Approach 2"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-used-model class=md-nav__link> <span class=md-ellipsis> 4.1 Used Model </span> </a> </li> <li class=md-nav__item> <a href=#42-dataset-for-fine-tuning class=md-nav__link> <span class=md-ellipsis> 4.2 Dataset for fine-tuning </span> </a> </li> <li class=md-nav__item> <a href=#43-steps-for-generating-summaries class=md-nav__link> <span class=md-ellipsis> 4.3 Steps for generating summaries </span> </a> </li> <li class=md-nav__item> <a href=#44-results-on-train-dataset class=md-nav__link> <span class=md-ellipsis> 4.4 Results on train dataset </span> </a> </li> <li class=md-nav__item> <a href=#45-discussion class=md-nav__link> <span class=md-ellipsis> 4.5 Discussion </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5-approach-3 class=md-nav__link> <span class=md-ellipsis> 5 Approach 3 </span> </a> <nav class=md-nav aria-label="5 Approach 3"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51-principle class=md-nav__link> <span class=md-ellipsis> 5.1 Principle </span> </a> </li> <li class=md-nav__item> <a href=#52-process class=md-nav__link> <span class=md-ellipsis> 5.2 Process </span> </a> </li> <li class=md-nav__item> <a href=#53-results-on-train-dataset class=md-nav__link> <span class=md-ellipsis> 5.3 Results on train dataset </span> </a> </li> <li class=md-nav__item> <a href=#54-fine-tuning-the-abstractive-model class=md-nav__link> <span class=md-ellipsis> 5.4 Fine-tuning the abstractive model </span> </a> </li> <li class=md-nav__item> <a href=#55-results-on-test-dataset class=md-nav__link> <span class=md-ellipsis> 5.5 Results on test dataset </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-conclusion class=md-nav__link> <span class=md-ellipsis> 6 Conclusion </span> </a> </li> <li class=md-nav__item> <a href=#project-members class=md-nav__link> <span class=md-ellipsis> Project Members </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../bot_detection_in_auction/ class=md-nav__link> <span class=md-ellipsis> Bots Detection in Auction </span> </a> </li> <li class=md-nav__item> <a href=../demand-forecasting-gui/ class=md-nav__link> <span class=md-ellipsis> Demand Forecasting GUI </span> </a> </li> <li class=md-nav__item> <a href=../driver-traffic-analysis/ class=md-nav__link> <span class=md-ellipsis> Driver Traffic Analysis </span> </a> </li> <li class=md-nav__item> <a href=../event-websites-and-org/ class=md-nav__link> <span class=md-ellipsis> Event Websites and Organizations </span> </a> </li> <li class=md-nav__item> <a href=../ozone-level-forecasting/ class=md-nav__link> <span class=md-ellipsis> Ozone Level Forecasting </span> </a> </li> <li class=md-nav__item> <a href=../public-admin-data-etl/ class=md-nav__link> <span class=md-ellipsis> Public Admin Data ETL </span> </a> </li> <li class=md-nav__item> <a href=../spring-school-etl-system/ class=md-nav__link> <span class=md-ellipsis> Spring School ETL System </span> </a> </li> <li class=md-nav__item> <a href=../statistical-methods-library/ class=md-nav__link> <span class=md-ellipsis> Statistical Methods Library </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../../blog/ class="md-nav__link "> <span class=md-ellipsis> Blog </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../blog/archive/2025/ class=md-nav__link> <span class=md-ellipsis> 2025 </span> </a> </li> <li class=md-nav__item> <a href=../../blog/archive/2024/ class=md-nav__link> <span class=md-ellipsis> 2024 </span> </a> </li> <li class=md-nav__item> <a href=../../blog/archive/2023/ class=md-nav__link> <span class=md-ellipsis> 2023 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../blog/category/authentication/ class=md-nav__link> <span class=md-ellipsis> Authentication </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/best-practices/ class=md-nav__link> <span class=md-ellipsis> Best Practices </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/blog/ class=md-nav__link> <span class=md-ellipsis> Blog </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/osx/ class=md-nav__link> <span class=md-ellipsis> OSX </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/rdp/ class=md-nav__link> <span class=md-ellipsis> RDP </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/security/ class=md-nav__link> <span class=md-ellipsis> Security </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/ai-tools/ class=md-nav__link> <span class=md-ellipsis> ai tools </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/beginners/ class=md-nav__link> <span class=md-ellipsis> beginners </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/clerck/ class=md-nav__link> <span class=md-ellipsis> clerck </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/cli-tools/ class=md-nav__link> <span class=md-ellipsis> cli-tools </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/code-quality/ class=md-nav__link> <span class=md-ellipsis> code-quality </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/containers/ class=md-nav__link> <span class=md-ellipsis> containers </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/conversion-tools/ class=md-nav__link> <span class=md-ellipsis> conversion-tools </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/data/ class=md-nav__link> <span class=md-ellipsis> data </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/data-validation/ class=md-nav__link> <span class=md-ellipsis> data-validation </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/data-visualization/ class=md-nav__link> <span class=md-ellipsis> data-visualization </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/database-management/ class=md-nav__link> <span class=md-ellipsis> database-management </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/dependency-management/ class=md-nav__link> <span class=md-ellipsis> dependency-management </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/deployment/ class=md-nav__link> <span class=md-ellipsis> deployment </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/dev/ class=md-nav__link> <span class=md-ellipsis> dev </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/docker/ class=md-nav__link> <span class=md-ellipsis> docker </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/documentation/ class=md-nav__link> <span class=md-ellipsis> documentation </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/domain-migration/ class=md-nav__link> <span class=md-ellipsis> domain-migration </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/fastapi/ class=md-nav__link> <span class=md-ellipsis> fastapi </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/file-handling/ class=md-nav__link> <span class=md-ellipsis> file-handling </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/flask/ class=md-nav__link> <span class=md-ellipsis> flask </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/frameworks/ class=md-nav__link> <span class=md-ellipsis> frameworks </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/frontend/ class=md-nav__link> <span class=md-ellipsis> frontend </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/fullstack/ class=md-nav__link> <span class=md-ellipsis> fullstack </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/fundamentals/ class=md-nav__link> <span class=md-ellipsis> fundamentals </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/git/ class=md-nav__link> <span class=md-ellipsis> git </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/github-pages/ class=md-nav__link> <span class=md-ellipsis> github-pages </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/gprc/ class=md-nav__link> <span class=md-ellipsis> gprc </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/huggingface/ class=md-nav__link> <span class=md-ellipsis> huggingface </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/intermediate/ class=md-nav__link> <span class=md-ellipsis> intermediate </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/javascript/ class=md-nav__link> <span class=md-ellipsis> javascript </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/laravel/ class=md-nav__link> <span class=md-ellipsis> laravel </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/linux/ class=md-nav__link> <span class=md-ellipsis> linux </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/logging/ class=md-nav__link> <span class=md-ellipsis> logging </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/markdown/ class=md-nav__link> <span class=md-ellipsis> markdown </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/microservices/ class=md-nav__link> <span class=md-ellipsis> microservices </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/mkdocs/ class=md-nav__link> <span class=md-ellipsis> mkdocs </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/mongodb/ class=md-nav__link> <span class=md-ellipsis> mongodb </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/mysql/ class=md-nav__link> <span class=md-ellipsis> mysql </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/networking/ class=md-nav__link> <span class=md-ellipsis> networking </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/nextjs/ class=md-nav__link> <span class=md-ellipsis> nextjs </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/nginx/ class=md-nav__link> <span class=md-ellipsis> nginx </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/nodejs/ class=md-nav__link> <span class=md-ellipsis> nodejs </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/numerical-analysis/ class=md-nav__link> <span class=md-ellipsis> numerical-analysis </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/package-manager/ class=md-nav__link> <span class=md-ellipsis> package-manager </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/packaging/ class=md-nav__link> <span class=md-ellipsis> packaging </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/php/ class=md-nav__link> <span class=md-ellipsis> php </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/poetry/ class=md-nav__link> <span class=md-ellipsis> poetry </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/postgresql/ class=md-nav__link> <span class=md-ellipsis> postgresql </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/prisma/ class=md-nav__link> <span class=md-ellipsis> prisma </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/programming/ class=md-nav__link> <span class=md-ellipsis> programming </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/project-management/ class=md-nav__link> <span class=md-ellipsis> project-management </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/pwa/ class=md-nav__link> <span class=md-ellipsis> pwa </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/python/ class=md-nav__link> <span class=md-ellipsis> python </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/recovery/ class=md-nav__link> <span class=md-ellipsis> recovery </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/remote-access/ class=md-nav__link> <span class=md-ellipsis> remote-access </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/sphinx/ class=md-nav__link> <span class=md-ellipsis> sphinx </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/ssh/ class=md-nav__link> <span class=md-ellipsis> ssh </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/streamlit/ class=md-nav__link> <span class=md-ellipsis> streamlit </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/tools-comparison/ class=md-nav__link> <span class=md-ellipsis> tools-comparison </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/troubleshooting/ class=md-nav__link> <span class=md-ellipsis> troubleshooting </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/type-checking/ class=md-nav__link> <span class=md-ellipsis> type-checking </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/version-control/ class=md-nav__link> <span class=md-ellipsis> version-control </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/web/ class=md-nav__link> <span class=md-ellipsis> web </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/windows/ class=md-nav__link> <span class=md-ellipsis> windows </span> </a> </li> <li class=md-nav__item> <a href=../../blog/category/workflow/ class=md-nav__link> <span class=md-ellipsis> workflow </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-introduction class=md-nav__link> <span class=md-ellipsis> 1 Introduction </span> </a> </li> <li class=md-nav__item> <a href=#2-evaluation-metrics class=md-nav__link> <span class=md-ellipsis> 2 Evaluation metrics </span> </a> </li> <li class=md-nav__item> <a href=#3-approach-1 class=md-nav__link> <span class=md-ellipsis> 3 Approach 1 </span> </a> <nav class=md-nav aria-label="3 Approach 1"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-used-models class=md-nav__link> <span class=md-ellipsis> 3.1 Used Models </span> </a> </li> <li class=md-nav__item> <a href=#32-steps-for-generating-summaries class=md-nav__link> <span class=md-ellipsis> 3.2 Steps for generating summaries </span> </a> </li> <li class=md-nav__item> <a href=#33-results-on-train-dataset class=md-nav__link> <span class=md-ellipsis> 3.3 Results on train dataset </span> </a> </li> <li class=md-nav__item> <a href=#34-fine-tuning class=md-nav__link> <span class=md-ellipsis> 3.4 Fine-tuning </span> </a> </li> <li class=md-nav__item> <a href=#35-evaluation-and-discussion class=md-nav__link> <span class=md-ellipsis> 3.5 Evaluation and discussion </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-approach-2 class=md-nav__link> <span class=md-ellipsis> 4 Approach 2 </span> </a> <nav class=md-nav aria-label="4 Approach 2"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-used-model class=md-nav__link> <span class=md-ellipsis> 4.1 Used Model </span> </a> </li> <li class=md-nav__item> <a href=#42-dataset-for-fine-tuning class=md-nav__link> <span class=md-ellipsis> 4.2 Dataset for fine-tuning </span> </a> </li> <li class=md-nav__item> <a href=#43-steps-for-generating-summaries class=md-nav__link> <span class=md-ellipsis> 4.3 Steps for generating summaries </span> </a> </li> <li class=md-nav__item> <a href=#44-results-on-train-dataset class=md-nav__link> <span class=md-ellipsis> 4.4 Results on train dataset </span> </a> </li> <li class=md-nav__item> <a href=#45-discussion class=md-nav__link> <span class=md-ellipsis> 4.5 Discussion </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5-approach-3 class=md-nav__link> <span class=md-ellipsis> 5 Approach 3 </span> </a> <nav class=md-nav aria-label="5 Approach 3"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#51-principle class=md-nav__link> <span class=md-ellipsis> 5.1 Principle </span> </a> </li> <li class=md-nav__item> <a href=#52-process class=md-nav__link> <span class=md-ellipsis> 5.2 Process </span> </a> </li> <li class=md-nav__item> <a href=#53-results-on-train-dataset class=md-nav__link> <span class=md-ellipsis> 5.3 Results on train dataset </span> </a> </li> <li class=md-nav__item> <a href=#54-fine-tuning-the-abstractive-model class=md-nav__link> <span class=md-ellipsis> 5.4 Fine-tuning the abstractive model </span> </a> </li> <li class=md-nav__item> <a href=#55-results-on-test-dataset class=md-nav__link> <span class=md-ellipsis> 5.5 Results on test dataset </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-conclusion class=md-nav__link> <span class=md-ellipsis> 6 Conclusion </span> </a> </li> <li class=md-nav__item> <a href=#project-members class=md-nav__link> <span class=md-ellipsis> Project Members </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/hermann-web/blog/edit/master/docs/projects/abstract-summarization.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/hermann-web/blog/raw/master/docs/projects/abstract-summarization.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=nlp-project-summarization>NLP Project: Summarization<a class=headerlink href=#nlp-project-summarization title="Permanent link">&para;</a></h1> <h2 id=1-introduction>1 Introduction<a class=headerlink href=#1-introduction title="Permanent link">&para;</a></h2> <p>Automatic text summarization is the process of condensing text into a shorter, key-information-retaining version. Abstract summarization, which focuses on reducing an abstract to a few sentences, is crucial in fields like scientific research for summarizing papers.</p> <p>Recent advancements in machine learning, natural language processing, and deep learning have significantly progressed automatic summarization. Despite this, it remains challenging as models must grasp text meaning and structure to produce accurate and readable summaries.</p> <p>This project explores various automatic summarization techniques, emphasizing pre-trained models and fine-tuning. We use a news article dataset, evaluating model performance with ROUGE and BLEU metrics to understand the strengths and limitations of different approaches and identify strategies for improving summary quality.</p> <p>We investigated three approaches:</p> <ol> <li>Using a high-performing pre-trained model, then fine-tuning a lower-performing model on a data subset, and evaluating it on a test set.</li> <li>Fine-tuning a model on a different dataset and applying it to our dataset for summarization.</li> <li>Employing a pre-trained extractive model to generate summaries, then fine-tuning an abstractive model on those summaries.</li> </ol> <h2 id=2-evaluation-metrics>2 Evaluation metrics<a class=headerlink href=#2-evaluation-metrics title="Permanent link">&para;</a></h2> <p>We utilize ROUGE-1, ROUGE-2, ROUGE-L, and BLEU as evaluation metrics. Here's how they're calculated in text summarization:</p> <ul> <li> <p><strong>ROUGE-1 = (number of overlapping unigrams) / (total number of unigrams in the reference summary)</strong> To calculate ROUGE-1, both the generated and reference summaries are tokenized into unigrams (single words). The count of shared unigrams is divided by the total unigrams in the reference summary, measuring shared words at the unigram level.</p> </li> <li> <p><strong>ROUGE-2 = (number of overlapping bigrams) / (total number of bigrams in the reference summary)</strong> For ROUGE-2, summaries are tokenized into bigrams (pairs of adjacent words). The number of shared bigrams is divided by the total bigrams in the reference summary, indicating shared adjacent word pairs.</p> </li> <li> <p><strong>ROUGE-L = (length of the longest common subsequence) / (total number of words in the reference summary)</strong> ROUGE-L is calculated by first finding the longest common subsequence (LCS) between the generated and reference summaries. The LCS length is then divided by the total words in the reference summary, showing how much of the reference summary is captured at the subsequence level.</p> </li> <li> <p><strong>BLEU = expmin(0,1-n/r) * (product of precision scores for n-grams)</strong> BLEU involves tokenizing both summaries into n-grams (typically 1 to 4). Precision for each n-gram set in the generated summary is calculated by dividing shared n-grams by total n-grams. The geometric mean of these precisions is then multiplied by a brevity penalty term (expmin(0,1-n/r), where 'n' is generated summary length and 'r' is reference summary length), assessing n-gram presence while considering length.</p> </li> </ul> <h2 id=3-approach-1>3 Approach 1<a class=headerlink href=#3-approach-1 title="Permanent link">&para;</a></h2> <p>Abstract summarization is a complex task involving condensing long texts into concise, essence-capturing sentences. In this approach, we apply pre-trained deep learning models and fine-tuning to summarize scientific abstracts on AI in agriculture. We compare model performance using Rouge 1, Rouge 2, Rouge L, and BLEU to identify the best and second-best models. To further enhance performance, we fine-tune the second-best model's summaries using those of the best model. This systematic approach aims to generate accurate and effective abstract summaries, valuable for document summarization and information retrieval.</p> <h3 id=31-used-models>3.1 Used Models<a class=headerlink href=#31-used-models title="Permanent link">&para;</a></h3> <p>The three pre-trained models are:</p> <ul> <li><strong>Big Bird Pegasus For Conditional Generation (BBPCG):</strong> BBPCG is a cutting-edge language model with a hybrid Transformer and sequence-to-sequence architecture, excelling in conditional text generation. It processes long inputs and generates high-quality summaries, utilizing an efficient pre-training method for impressive results in text summarization, language modeling, and machine translation.</li> <li><strong>Pegasus-xsum (pegasus):</strong> Pegasus-Xsum is a powerful language model for text summarization, leveraging the Transformer architecture to create high-quality summaries from long inputs. Pre-trained on a vast web text corpus, it generates grammatically correct and semantically accurate summaries. Its decoding strategy includes a length penalty to ensure optimal summary length. Pegasus-Xsum achieves state-of-the-art performance on benchmark summarization datasets.</li> <li><strong>t5-large-finetuned-xsum-cnn (t5-large):</strong> This language model is fine-tuned on the CNN/Daily Mail summarization dataset using the T5 Transformer architecture, generating high-quality summaries that capture news article key information effectively. T5-Large-Finetuned-Xsum-CNN combines large corpus pre-training with summarization task fine-tuning for accurate and fluent summaries, demonstrating superior performance on CNN/Daily Mail and other benchmark datasets.</li> </ul> <h3 id=32-steps-for-generating-summaries>3.2 Steps for generating summaries<a class=headerlink href=#32-steps-for-generating-summaries title="Permanent link">&para;</a></h3> <p>The summaries are generated following these main steps:</p> <ol> <li>Import the model and tokenizer.</li> <li>Move the model to a specified device (CPU or GPU); in our case, all calculations are performed using GPU in Collab.</li> <li>Set batch size and maximum summary length as hyperparameters.</li> <li>Create an empty list <code>summaries</code> to store the generated summaries.</li> <li>Loop through the abstracts in the training dataset in batches of size <code>batch_size</code>.<ul> <li>Tokenize the batch of abstracts using the tokenizer.</li> <li>Generate summaries for each batch using the specified <code>max_summary_length</code> and the model.</li> <li>The model's <code>generate</code> method takes encoded input sequences, uses beam search to produce corresponding output sequences, and returns the resulting tensor of output token IDs.</li> <li>Decode the generated token IDs into human-readable text summaries using the tokenizer.</li> <li>Add the batch of summaries to the <code>summaries</code> list.</li> </ul> </li> </ol> <h3 id=33-results-on-train-dataset>3.3 Results on train dataset<a class=headerlink href=#33-results-on-train-dataset title="Permanent link">&para;</a></h3> <p>We generated summaries for <code>train_dataset.json</code> for fine-tuning and evaluated performance on <code>test_dataset.json</code>. The results for <code>train_dataset.json</code> are as follows:</p> <table> <thead> <tr> <th style="text-align: left;">model</th> <th style="text-align: left;">ROUGE-1</th> <th style="text-align: left;">ROUGE-2</th> <th style="text-align: left;">ROUGE-L</th> <th style="text-align: left;">BLEU</th> </tr> </thead> <tbody> <tr> <td style="text-align: left;">t5-large-finetuned-xsum-cnn</td> <td style="text-align: left;">0.169237</td> <td style="text-align: left;">0.069559</td> <td style="text-align: left;">0.158777</td> <td style="text-align: left;">2.746262e-243</td> </tr> <tr> <td style="text-align: left;">BBPCG</td> <td style="text-align: left;">0.122082</td> <td style="text-align: left;">0.024987</td> <td style="text-align: left;">0.113230</td> <td style="text-align: left;">7.539752e-214</td> </tr> <tr> <td style="text-align: left;">pegasus-xsum</td> <td style="text-align: left;">0.229497</td> <td style="text-align: left;">0.078772</td> <td style="text-align: left;">0.210326</td> <td style="text-align: left;">4.516283e-215</td> </tr> </tbody> </table> <p><em>Table 1: Evaluation metrics for different models on the training dataset.</em></p> <p>The table displays the performance of three text summarization models: <code>t5 – large – finetuned – xsum – cnn</code>, <code>BigBirdPegasusForConditionalGeneration_summaries</code>, and <code>pegasus – xsum_summary</code>, across ROUGE-1, ROUGE-2, ROUGE-L, and BLEU metrics. The <code>pegasus – xsum_summary</code> model achieved the highest scores in all metrics, followed by <code>t5 – large – finetuned – xsum – cnn</code>. The <code>BigBirdPegasusForConditionalGeneration_summaries</code> model had the lowest scores. This suggests <code>pegasus – xsum_summary</code> may be the most effective for text summarization tasks among these models. However, these results are based on a specific dataset and may not generalize to other datasets or use cases.</p> <h3 id=34-fine-tuning>3.4 Fine-tuning<a class=headerlink href=#34-fine-tuning title="Permanent link">&para;</a></h3> <p>In this section, we generate summaries from the top-performing model (pegasus) to fine-tune the second-best model (t5-large). We use a dataset named <code>train_dataset.json</code>, which contains abstracts and their corresponding summaries from the pegasus model.</p> <p>Fine-tuning the T5-Large model for text summarization involves training it on a specific summarization task. This entails providing the model with a large dataset of input-output text pairs, where the input is a longer document and the output is a shorter summary. The model learns to generate summaries by adjusting its parameters based on these training examples, fine-tuning hyperparameters like learning rate and batch size, and optimizing the loss function to enhance performance. Once fine-tuning is complete, the T5-Large model can generate summaries for new documents and has demonstrated state-of-the-art results when fine-tuned on diverse datasets.</p> <p><strong>Note:</strong> Due to computational limitations, we used a dataset of 300 samples for fine-tuning. On average, summarizing one abstract takes about 1.5 minutes, totaling 100 hours for 4000 samples in the original dataset for a single model.</p> <h3 id=35-evaluation-and-discussion>3.5 Evaluation and discussion<a class=headerlink href=#35-evaluation-and-discussion title="Permanent link">&para;</a></h3> <p>To evaluate the ensemble of models and approaches, we used a fixed test dataset called <code>test_dataset.json</code>, applying all our models and ideas with the four metrics. The table below shows the results of the three models and the fine-tuned one:</p> <table> <thead> <tr> <th style="text-align: left;">Model</th> <th style="text-align: left;">ROUGE-1</th> <th style="text-align: left;">ROUGE-2</th> <th style="text-align: left;">ROUGE-L</th> <th style="text-align: left;">BLEU</th> </tr> </thead> <tbody> <tr> <td style="text-align: left;">BBPCG</td> <td style="text-align: left;">0.128516</td> <td style="text-align: left;">0.029043</td> <td style="text-align: left;">0.118884</td> <td style="text-align: left;">1.241677e-10</td> </tr> <tr> <td style="text-align: left;">Pegasus</td> <td style="text-align: left;">0.199311</td> <td style="text-align: left;">0.055300</td> <td style="text-align: left;">0.186434</td> <td style="text-align: left;">5.717189e-215</td> </tr> <tr> <td style="text-align: left;">T5_large</td> <td style="text-align: left;">0.186353</td> <td style="text-align: left;">0.082153</td> <td style="text-align: left;">0.177092</td> <td style="text-align: left;">1.226987e-240</td> </tr> <tr> <td style="text-align: left;">T5_fine_tunned_on_Pegasus</td> <td style="text-align: left;">0.163148</td> <td style="text-align: left;">0.052152</td> <td style="text-align: left;">0.147984</td> <td style="text-align: left;">2.347712e-235</td> </tr> </tbody> </table> <p><em>Table 2: Evaluation metrics for different models on test data.</em></p> <p>The results indicate that the "pegasus_summaries" model outperforms others across all evaluation metrics. Its Rouge-1 score of 0.199 is significantly higher, demonstrating better capture of important abstract information. The high Rouge-2 score (0.055) shows its ability to capture key phrases and word combinations, while the Rouge-L score (0.186) indicates good coherence and overall meaning retention.</p> <p>The "t5_large" model ranks second, with Rouge-2 and Rouge-L scores similar to "pegasus," but a slightly lower Rouge-1 score. This suggests it captures overall meaning well but may be less effective at extracting the most critical information than the best model.</p> <p>The "t5_fine_tuned_on_pegasus" model, fine-tuned on summaries generated by "pegasus," performed worse than the second-best model. This indicates that fine-tuning on summaries from another model may not always yield superior results.</p> <p>The "BBPCG" model performed significantly worse than others across all metrics, possibly due to its unsuitability for abstract summarization tasks or lack of fine-tuning on an appropriate dataset.</p> <p>Overall, "pegasus" appears to be the best model for abstract summarization among those evaluated. However, factors like the training dataset and specific task requirements can influence the optimal model choice.</p> <p>Fine-tuning a pre-trained language model on a specific dataset can improve performance on downstream tasks. However, in this case, fine-tuning the "t5_large" model for abstract summarization did not yield the expected improvement. This could be due to the small fine-tuning dataset, which may not have captured the task's complexity, or the mismatch between the fine-tuning dataset and the original pre-trained model's training data, limiting the effectiveness of fine-tuning.</p> <h2 id=4-approach-2>4 Approach 2<a class=headerlink href=#4-approach-2 title="Permanent link">&para;</a></h2> <p>In this second approach, we present an abstract summarization method using pre-trained deep learning models and fine-tuning. Specifically, we employed a pre-trained T5 (Text-to-Text Transfer Transformer) model, which was fine-tuned on XSum, a dataset of news articles and their summaries. We then used this fine-tuned model to summarize 400 abstracts from our dataset. The model's performance was evaluated using metrics such as Rouge 1, Rouge 2, Rouge L, and BLEU.</p> <h3 id=41-used-model>4.1 Used Model<a class=headerlink href=#41-used-model title="Permanent link">&para;</a></h3> <p><strong>Text-to-Text Transfer Transformer (T5-small):</strong> T5-small is a pre-trained version of the T5 model with 220 million parameters, making it smaller than T5-3B and T5-11B. It is trained on diverse unsupervised and supervised tasks, utilizing self-attention to learn contextual text representations. T5-small can be fine-tuned on specific tasks with limited labeled data, and it has achieved state-of-the-art performance in natural language processing tasks such as summarization, translation, and question answering. Its adaptable and unified training framework makes it suitable for a wide range of text-to-text tasks.</p> <h3 id=42-dataset-for-fine-tuning>4.2 Dataset for fine-tuning<a class=headerlink href=#42-dataset-for-fine-tuning title="Permanent link">&para;</a></h3> <p><strong>Extreme Summarization (Xsum):</strong> For this project, we utilized the XSum dataset (Narayan and Gardent, 2018), a collection of approximately 226,000 news articles from various sources, each with a one-sentence summary. To adapt this dataset, we focused on articles related to agriculture, selecting a subset of 400 articles for fine-tuning our model.</p> <h3 id=43-steps-for-generating-summaries>4.3 Steps for generating summaries<a class=headerlink href=#43-steps-for-generating-summaries title="Permanent link">&para;</a></h3> <p>The summaries are generated following these main steps using the GPU provided on Google Colab:</p> <ol> <li>Import necessary libraries, including Hugging Face Transformers and Datasets.</li> <li>Load and tokenize the dataset using the Datasets library.</li> <li>Download and load the pre-trained T5 model checkpoint from the Hugging Face Model Hub.</li> <li> <p>Define a special data collator for sequence-to-sequence models using <code>DataCollatorForSeq2Seq</code> from the Transformers library. This collator creates input IDs, attention masks, and labels.</p> </li> <li> <p>Define the optimizer and compile the model using the Adam optimizer and the built-in loss calculation function.</p> </li> <li>Train the model with specified hyperparameters (learning_rate=2e-5, batch_size=8, max_input_length=1024, min_target_length=150, max_target_length=250) using the training and validation sets, and the defined metric function for calculating ROUGE scores. We use only 10% for training and 10% for validation due to hardware and time limitations.</li> <li>Generate summaries using the trained model and the summarization pipeline from the Transformers library. The pipeline method takes the trained model and tokenizer as arguments and uses the summarization pipeline.</li> <li>Use metrics such as BLEU, ROUGE-1, ROUGE-2, and ROUGE-L to evaluate the results.</li> </ol> <h3 id=44-results-on-train-dataset>4.4 Results on train dataset<a class=headerlink href=#44-results-on-train-dataset title="Permanent link">&para;</a></h3> <p>We started by generating summaries on both <code>train_dataset.json</code> and <code>test_dataset.json</code>. Then, we evaluated the performances. The results are as follows:</p> <table> <thead> <tr> <th style="text-align: left;">model</th> <th style="text-align: left;">ROUGE-1</th> <th style="text-align: left;">ROUGE-2</th> <th style="text-align: left;">ROUGE-L</th> <th style="text-align: left;">BLEU</th> </tr> </thead> <tbody> <tr> <td style="text-align: left;">T5-small-finetuned-on-Xsum</td> <td style="text-align: left;">0.362165</td> <td style="text-align: left;">0.217916</td> <td style="text-align: left;">0.338231</td> <td style="text-align: left;">1.130762e-10</td> </tr> </tbody> </table> <p><em>Table 3: Evaluation metrics for the model.</em></p> <p>The table shows the performance of the <code>t5small</code> model fine-tuned on X_sum using ROUGE-1, ROUGE-2, ROUGE-L, and BLEU metrics. The results indicate that this fine-tuning approach yielded lower scores compared to the first approach using large models. This suggests that the <code>pegasus – xsum_summary</code> model might be more effective for text summarization tasks. However, this performance could be attributed to the model being fine-tuned on only 10% of Xsum for a single epoch.</p> <h3 id=45-discussion>4.5 Discussion<a class=headerlink href=#45-discussion title="Permanent link">&para;</a></h3> <ol> <li> <p>A limitation of this approach is the small amount of training data used. Fine-tuning a pre-trained model on only 10% of the X-sum dataset might not be enough to capture the task's nuances, potentially leading to suboptimal results. Increasing the training data and/or the number of training epochs could improve model performance.</p> </li> <li> <p>The choice of pre-trained model could also affect the quality of generated summaries. While T5 is powerful, other models might be better suited for summarization. Larger models, like those used in the other approach, could have contributed to better performance.</p> </li> <li> <p>Additionally, the quality of the input data can impact model performance. X-sum, a news article dataset, varies widely in topic, tone, and complexity, making some articles harder to summarize. Using an agriculture-specific dataset could enhance performance.</p> </li> <li> <p>Finally, ROUGE scores may not fully capture summary quality. While quantitative, they don't account for coherence, fluency, or readability. Therefore, a qualitative evaluation through manual inspection or user studies is crucial for a complete picture of the model's performance.</p> </li> </ol> <h2 id=5-approach-3>5 Approach 3<a class=headerlink href=#5-approach-3 title="Permanent link">&para;</a></h2> <h3 id=51-principle>5.1 Principle<a class=headerlink href=#51-principle title="Permanent link">&para;</a></h3> <p>Abstractive summarization creates human-like summaries by interpreting and paraphrasing text for brevity and readability. This approach uses advanced NLP techniques, deep learning, and neural networks to understand text meaning and generate new, accurate language. While often more readable, it's more complex and can be less accurate than extractive summarization. Extractive summarization, conversely, selects and combines key sentences or phrases from the original text to form a concise and accurate summary. It can be effective for conveying main points, is easier to train with less data, and produces easier-to-evaluate summaries. Therefore, we used an extractive model to generate summaries for our training dataset, which will then be used for fine-tuning an abstractive model.</p> <p>Here are the steps we followed:</p> <ol> <li> <p><strong>Choose the extractive model and apply it to the train dataset:</strong> We selected <code>bart_large_xsum_samsum</code> as our abstractive extractive model. Developed by Facebook AI Research, this language model is pre-trained on a large text corpus, specifically designed for summarization and question answering. Its training data combines the XSUM dataset (manually summarized BBC news articles) and the SAMSUM dataset (questions and answers from Wikipedia articles). The BART model architecture is transformer-based, effective for NLP tasks. <code>bart_large_xsum_samsum</code>, a large variant with 406 million parameters, was applied to our training dataset of 300 abstracts, and the resulting summaries were collected.</p> </li> <li> <p><strong>Choose the abstractive model and fine-tune it with the results of the abstractive extractive model:</strong> We selected <code>t5_large_finetuned_xsum</code> as our abstractive model. This T5 model is fine-tuned on the XSum dataset, which comprises short news articles with single-sentence summaries. The "large" in "t5-large" signifies its 770 million parameters, making it more powerful than base or small T5 versions. Recognized as a powerful tool for text summarization, it has achieved state-of-the-art performance on various benchmark datasets. We fine-tuned this model using the summaries generated by the first model and tested it on our test dataset of 100 abstracts.</p> </li> </ol> <h3 id=52-process>5.2 Process<a class=headerlink href=#52-process title="Permanent link">&para;</a></h3> <ol> <li>Load/install the necessary libraries.</li> <li>Load the dataset train.</li> <li>Load the abstractive extractive model: bart large xsum samsum.</li> <li>Apply the bart large xsum samsum model to the train dataset.</li> <li>Create a new dataset containing the abstracts of the dataset train and their summaries obtained by applying the extractive abstractive model.</li> <li>Tokenize the new dataset.</li> <li>Load the template abstractive: t5 large finetuned xsum.</li> <li>Define the hyperparameters.</li> <li>Fine tune the t5 large finetuned xsum model.</li> <li>Apply the fine tuned model on the test dataset.</li> <li>Calculate the metrics needed to evaluate the fine tuned model.</li> </ol> <h3 id=53-results-on-train-dataset>5.3 Results on train dataset<a class=headerlink href=#53-results-on-train-dataset title="Permanent link">&para;</a></h3> <p>We generated abstracts for <code>train_dataset.json</code> for fine-tuning and then evaluated the performance of the fine-tuned abstractive model on <code>train_dataset.json</code>. The results on <code>train_dataset.json</code> are as follows:</p> <table> <thead> <tr> <th style="text-align: left;">model</th> <th style="text-align: left;">ROUGE-1</th> <th style="text-align: left;">ROUGE-2</th> <th style="text-align: left;">ROUGE-L</th> <th style="text-align: left;">BLEU</th> </tr> </thead> <tbody> <tr> <td style="text-align: left;">Extractive model bart_large_xsum_samsum</td> <td style="text-align: left;">0.356324</td> <td style="text-align: left;">0.244907</td> <td style="text-align: left;">0.350222</td> <td style="text-align: left;">1.701539e-222</td> </tr> <tr> <td style="text-align: left;">Abstractive model t5_large_finetuned_xsum</td> <td style="text-align: left;">0.156297</td> <td style="text-align: left;">0.044861</td> <td style="text-align: left;">0.1397918</td> <td style="text-align: left;">3.610569e-239</td> </tr> </tbody> </table> <p><em>Table 4: Evaluation metrics for different models.</em></p> <p>The table shows the performance of two different models on four evaluation metrics commonly used in text summarization: ROUGE-1, ROUGE-2, ROUGE-L, and BLEU.</p> <p>The first model is an extractive model called "bart_large_xsum_samsum", and the second model is an abstractive model called "t5_large_finetuned_xsum".</p> <p>In terms of performance, the extractive model outperforms the abstractive model on all four evaluation metrics. Specifically, the extractive model achieves ROUGE-1, ROUGE-2, and ROUGE-L scores of 0.356, 0.245, and 0.350, respectively, while the abstractive model achieves scores of 0.156, 0.045, and 0.140, respectively. The extractive model also achieves a higher BLEU score of 1.701539e-222 compared to the abstractive model's score of 3.610569e-239.</p> <h3 id=54-fine-tuning-the-abstractive-model>5.4 Fine-tuning the abstractive model<a class=headerlink href=#54-fine-tuning-the-abstractive-model title="Permanent link">&para;</a></h3> <p>Extractive summarization methods identify and select crucial sentences or phrases from a source document, then stitch them together to form a summary. These summaries tend to be more factually accurate and capture the main ideas. By providing these extractive summaries as inputs to the abstractive model during fine-tuning, the abstractive model can learn from these important sentences and phrases, generating more accurate and informative summaries. This approach helps the abstractive model focus on key information, avoiding errors or irrelevant details.</p> <h3 id=55-results-on-test-dataset>5.5 Results on test dataset<a class=headerlink href=#55-results-on-test-dataset title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th style="text-align: left;">model</th> <th style="text-align: left;">ROUGE-1</th> <th style="text-align: left;">ROUGE-2</th> <th style="text-align: left;">ROUGE-L</th> <th style="text-align: left;">BLEU</th> </tr> </thead> <tbody> <tr> <td style="text-align: left;">Abstractive model</td> <td style="text-align: left;">0.166340</td> <td style="text-align: left;">0.049878</td> <td style="text-align: left;">0.148912</td> <td style="text-align: left;">5.442148e-235</td> </tr> <tr> <td style="text-align: left;">Finetuned Abstractive model</td> <td style="text-align: left;">0.141666</td> <td style="text-align: left;">0.037907</td> <td style="text-align: left;">0.128724</td> <td style="text-align: left;">3.023488e-241</td> </tr> </tbody> </table> <p><em>Table 5: Evaluation metrics for different models.</em></p> <p>The fine-tuned abstractive model's performance was evaluated using standard metrics (ROUGE-1, ROUGE-2, ROUGE-L, and BLEU). The results showed lower scores across all metrics compared to the pre-trained model. This is a common challenge in fine-tuning, as it requires balancing pre-trained knowledge with adaptation to a new domain. It's possible the original model's pre-trained knowledge wasn't fully compatible with the extractive summaries used for fine-tuning, leading to a performance decrease.</p> <p>Another potential reason for reduced performance is the quality of the extractive summaries used during fine-tuning. Extractive summarization methods aren't perfect; they can sometimes miss important information or include irrelevant details. Using lower-quality extractive summaries for fine-tuning could lead to the abstractive model learning from incorrect or incomplete information, resulting in decreased performance.</p> <h2 id=6-conclusion>6 Conclusion<a class=headerlink href=#6-conclusion title="Permanent link">&para;</a></h2> <p>In conclusion, the three approaches presented describe different methods for abstract summarization using pre-trained deep learning models and fine-tuning techniques. The first approach focused on using three large pre-trained models and fine-tuning the second-best model on the best model's summaries to enhance performance. The second approach used a single pre-trained model fine-tuned on a small subset of news articles in the agriculture domain. The third approach employed an abstractive-extractive hybrid method, first using an extractive model to generate summaries and then fine-tuning an abstractive model on those summaries.</p> <p>While each approach has strengths and limitations, evaluation metrics suggest that the first approach achieved the highest scores across all metrics, followed by the third and second approaches. However, it's crucial to note that the metrics used (BLEU, ROUGE-1, ROUGE-2, and ROUGE-L) don't always fully capture the quality or coherence of generated summaries.</p> <p>Overall, these approaches offer valuable insights into various abstract summarization methods and how pre-trained deep learning models and fine-tuning can improve performance. These methods have potential applications in document summarization, information retrieval, and other areas requiring summary generation.</p> <h2 id=project-members>Project Members<a class=headerlink href=#project-members title="Permanent link">&para;</a></h2> <ul> <li>Wiam ADNAN</li> <li>Aymane Hanine</li> <li>Salma KHMASSI</li> <li>Hermann Agossou</li> <li>Zakaria Taouil</li> </ul> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="November 22, 2025 21:58:00 CET"><span class=timeago datetime=2025-11-22T21:58:00+01:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="November 22, 2025 21:58:00 CET">2025-11-22</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="November 22, 2025 21:58:00 CET"><span class=timeago datetime=2025-11-22T21:58:00+01:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="November 22, 2025 21:58:00 CET">2025-11-22</span> </span> </aside> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5 9v12H1V9zm4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21zm0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03z"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 15V3h4v12zM15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3zm0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97z"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! </div> </div> </div> </fieldset> </form> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../introducing-lissajou-for-animated-plots/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Introducing the `lissajou` Package for Image and 2D/3D Plot Animation"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Introducing the `lissajou` Package for Image and 2D/3D Plot Animation </div> </div> </a> <a href=../bot_detection_in_auction/ class="md-footer__link md-footer__link--next" aria-label="Next: Bots Detection in Auction"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Bots Detection in Auction </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2023-2024 Hermann Agossou </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://www.github.com/hermann-web target=_blank rel=noopener title=www.github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://www.linkedin.com/in/agossou-hermann target=_blank rel=noopener title=www.linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href=https://www.hub.docker.com/r/hermann-web/hermann-agossou.com/ target=_blank rel=noopener title=www.hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg> </a> <a href=https://pypi.org/user/Hermann-web/ target=_blank rel=noopener title=pypi.org class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> <a href=https://www.researchgate.net/profile/Hermann-Agosou target=_blank rel=noopener title=www.researchgate.net class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M0 32v448h448V32zm262.2 334.4c-6.6 3-33.2 6-50-14.2-9.2-10.6-25.3-33.3-42.2-63.6-8.9 0-14.7 0-21.4-.6v46.4c0 23.5 6 21.2 25.8 23.9v8.1c-6.9-.3-23.1-.8-35.6-.8-13.1 0-26.1.6-33.6.8v-8.1c15.5-2.9 22-1.3 22-23.9V225c0-22.6-6.4-21-22-23.9V193c25.8 1 53.1-.6 70.9-.6 31.7 0 55.9 14.4 55.9 45.6 0 21.1-16.7 42.2-39.2 47.5 13.6 24.2 30 45.6 42.2 58.9 7.2 7.8 17.2 14.7 27.2 14.7zm22.9-135c-23.3 0-32.2-15.7-32.2-32.2V167c0-12.2 8.8-30.4 34-30.4s30.4 17.9 30.4 17.9l-10.7 7.2s-5.5-12.5-19.7-12.5c-7.9 0-19.7 7.3-19.7 19.7v26.8c0 13.4 6.6 23.3 17.9 23.3 14.1 0 21.5-10.9 21.5-26.8h-17.9v-10.7h30.4c0 20.5 4.7 49.9-34 49.9m-116.5 44.7c-9.4 0-13.6-.3-20-.8v-69.7c6.4-.6 15-.6 22.5-.6 23.3 0 37.2 12.2 37.2 34.5 0 21.9-15 36.6-39.7 36.6"/></svg> </a> <a href=https://www.twitter.com/AgossouHermann target=_blank rel=noopener title=www.twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": {"json": [".s2"]}, "base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.e71a0d61.min.js></script> <script src=../../js/timeago.min.js></script> <script src=../../js/timeago_mkdocs_material.js></script> <script src=../../javascripts/katex.js></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js></script> </body> </html>